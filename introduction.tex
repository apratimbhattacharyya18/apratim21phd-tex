\chapter{Introduction}
\label{chap:introduction}
\minitoc\vspace{2ex}
% human vision

\begin{chapquote}{Niels Bohr}
``Prediction is very difficult, especially if itâ€™s about the future!''
\end{chapquote}


\lettrine[lines=3]{A}{n}ticipation of the future is crucial for many day to day tasks.  Such day to day tasks include driving or playing sports.  While driving it is crucial to anticipate the path of other road users especially vulnerable users such as pedestrians  to avoid collisions. While playing sports such as soccer, it is crucial for the goal keeper to anticipate the path of the ball to stop the opposing team from scoring.  For autonomous agents to succeed in such real world tasks,  it is therefore also important to anticipate such future events. In this thesis, we focus on this challenging task of anticipating the future.  However, this task is clearly challenging and accurate long-term predictions even in the order of several seconds are even harder to make. 

The challenges involved depend largely upon the target scenario.  In some cases,  the scenario is largely governed by a set of deterministic rules e.g.\  the laws of physics in case of balls on a billiard table.  Making long-term predictions, in such scenarios is possible if these rules and all associated physical quantities e.g.\ the speed of the balls and coefficient of friction of the table are known apriori.  However,  accurately estimating the set of deterministic rules and the corresponding physical quantities of interest is challenging.  While it is definitely possible to hand-craft systems based on domain knowledge such systems would not generalize across scenarios.  Therefore,  a recent group of work \cite{fragkiadaki2015learning,lerer2016learning,li2016fall,battaglia2016interaction,watters2017visual},  broadly termed ``Intuitive Physics'' have focused on the development of methods which can learn these rules directly from the data without explicit human supervision.  This enables such methods to be broadly applicable to diverse scenarios.  In this thesis, we focus on highly flexible methods that can learn directly from raw video data and can make long-term predictions.

However,  many important real world scenarios e.g.\ in case of autonomous driving,  involve external agents such as pedestrians or vehicles.  The future states of such agents are dependent upon decisions made by the agents themselves,  which are very hard to anticipate.  This makes the future highly uncertain,  with many possible future outcomes even a few seconds into the future.  Methods ?? which aim to predict a single future outcome e.g.\ the most likely outcome, do not perform very well ?? as the single predicted future can be far away from the true outcome.  Therefore,  it is crucial to capture the distribution of likely futures ??.  Moreover,  the predicted distribution must be calibrated ?? -- the predicted uncertainty should correspond well to the observed (groundtruth) uncertainty.  Here,  we build upon scalable Bayesian Inference methods which provide calibrated uncertainty estimates while being computationally efficient.  

Additionally in many real world scenarios,  the distribution of likely future states is highly multi-modal.  In safely critical applications such as autonomous driving it is crucial to accurately capture all modes e.g.\ all likely paths that a pedestrian can take,  in order to avoid collisions.  Prior work has proposed methods based on conditional generative adversarial networks (cGAN),  however,  such cGAN based models suffer from well know issues such as mode collapse where one or modes of the target distribution are missed.  In this thesis,  we focus on conditional variational autoencoders (cVAE),  which unlike cGANs maximize a lower bound on the data log-likelihood and are therefore better at capturing all modes of the target data distribution.  However,  the  standard objective for training cVAEs does not sufficiently encourage diversity in predictions.  Furthermore,  the standard Gaussian prior used in cVAEs also makes it challenging to fully capture distribution of likely future states.  Here,  we focus on improving the objective used for training cVAEs to encourage accurate and diverse predictions.  Furthermore,  we propose more expressive priors to help better model the target distribution.

However,  both cGAN and cVAE based models do not maximize the exact data log-likelihood. This makes it challenging to capture multi-modal data distributions.  Recent work has therefore focused on exact inference models e.g.\ autoregressive models and normalizing flow based models, mostly on image data.  Autoregressive models, while having high modelling flexibility, are difficult to parallelize and thus suffer from slow sampling speeds. Normalizing flows on the other hand are easy to parallelize. Here, we focus on extending such normalizing flow based models for the task of future prediction. However, normalizing flow suffer from comparatively low modelling flexibility due to the invertibility constraints on it's internal layers. We therefore propose to combine normalizing flow based models with expressive autoregressive priors and   Haar-wavelet based block autoregressive structures to balance modelling flexibility and computational efficiency.

To summarize, in this thesis, we tackle the problem of anticipating the future upto several seconds in diverse scenarios ranging from billiard tables to street scenes. We target these scenarios because they are important for the success of autonomous agents in the real world e.g.\ in autonomous driving. We target three important challenges, \begin{enumerate*}
\item accurate long-term predictions,
\item uncertainty of future states in the long-term,
\item multi-modality of the distribution of likely future states in the long-term.
\end{enumerate*}. 
We deal with long-term predictions both in case of deterministic scenarios largely governed by the laws of physics and highly non-deterministic agent based scenarios. In both case, we show that choosing a suitable representation is crucial. We show that the prediction of image boundaries into the future is easier than predicting full RGB pixels and this allows us to develop an approach that can make long-range predictions from raw pixel data. To deal with the challenge of uncertainty, we develop Bayesian Inference methods for the task of future prediction. We show that efficient Monte Carlo dropout based Bayesian Inference methods can be successfully extended to the task of long-term on-board prediction of pedestrian trajectories, while yielding calibrated uncertainties. To deal with the challenge of multi-modality, we propose novel objectives and flexible priors for cVAE based models. We focus on cVAE based models as alternatives like cGANs do not explicitly maximize the data log-likelihood leading to missing modes. Finally, we turn our attention to normalizing flow based models, as they can maximize the exact data log-likelihood unlike both cGANs and cVAEs. We propose normalizing flow based models with improved modelling flexibility which leads to competitive results in comparison to cVAE and cGAN based models on highly multi-modal scenarios.   


\section{Main Thesis Contributions}
This thesis contributes to the broad areas of generative modelling, Bayesian inference, trajectory prediction and scene prediction in general. Next, we group the contributions of the thesis and place them in context of prior work in the field. 

\subsection{Long-term Prediction of Sequences} 
Long-term predictions even in scenarios which evolve through a set of deterministic rules is challenging.  It requires the estimation of the set of deterministic rules and the associated physical quantities. Hand crafted methods would not be widely applicable across diverse scenarios and would require repeated manual intervention. Therefore, the recent work \cite{fragkiadaki2015learning,lerer2016learning,li2016fall,battaglia2016interaction,watters2017visual} have focused on learning such rules directly from data in order to make predictions about the future. However, learning from raw video data for long-term predictions remains challenging. Issues such as blurriness are commonly reported. 

 In \cite{BhattacharyyaMS18}, we instead focus on learning from and predicting future image boundaries. Scene boundaries capture the important structure and extents of objects. Moreover, they can be accurately estimated \cite{khoreva2016improved}. This makes learning the dynamics of scene evolution and prediction considerably easier. We propose a fully convolutional CMSC model, which includes a wide receptive field allowing the model to learn complex spatio-temporal dependencies.  Accurate prediction at each time-step is additionally enabled by the lack of bottleneck layers.  Global consistency of predictions is enabled by a shared context which allows for information sharing. We obtain accurate long-term predictions, in contrast to prediction directly on RGB data, which leads to very blurry results in the long-term. Accurate predictions on diverse scenarios shows that our model developed a data-driven model of future motion and scene evolution over long time horizons.

Since the introduction of our boundary prediction method, learning the dynamics of evolution of complex scenes from raw visual data has remained an active area of research. 
In \cite{EhrhardtMMV18}, learning and prediction directly from raw visual observations is enabled by tracking dynamically-salient objects in videos using causality and equivariance. 
In \cite{abs-1904-09860} an end-to-end learning-based approach to predict stability directly from appearance is presented. 
Similarly, in \cite{abs-1809-03330} real images are first converted to a synthetic domain representation that reduces complexity arising from lighting and texture for accurate long-term prediction.

\subsection{Bayesian Inference for Modelling Uncertainty}
In case of scenarios such as street scenes, the future becomes highly uncertain due to the involvement of external agents whose actions are based on unknown internal states, e.g.\ pedestrians. Methods which predict a single deterministic future do not perform well in such scenarios. In fact, for safety critical applications such as autonomous driving, it is crucial to model the full distribution of likely futures e.g.\ the distribution of future pedestrian trajectories. 

In \cite{BhattacharyyaFS18},  we propose the first method for long-term prediction of pedestrian trajectories in a on-board scenario. We observe that in such scenarios with high uncertainty, given the data, there exists multiple models that can explain (predict) the observed future equally well (epistemic uncertainty) -- as there are multiple likely futures. Therefore, to capture the uncertainty in the distribution of likely futures, we aim to estimate this distribution of likely models.

We propose a novel two stream Bayesian RNN encoder-decoder model in  \cite{BhattacharyyaFS18}, where the distribution of likely models is inferred using dropout based Monte Carlo Bayesian Inference. The two streams in our model jointly predict  the pedestrian trajectory and the vehicle ego-motion for improved long-term prediction accuracy.  The distribution of likely models is represented by a Bernoulli distribution (dropout) on the two weight matrices of the RNN encoder and decoder.  The uncertainty introduced due to observation noise (aleatoric uncertainty) is captured by assuming a distribution of observation noise and estimating the sufficient statistics of the distribution. Our  two stream Bayesian RNN encoder-decoder model leads to accurate  predictions over a time horizon of 1 second on CityScapes. Moreover, we observe that the predicted uncertainty upper bounds the error of the mean of the predictive distribution. Therefore, the predicted uncertainty helps us express trust in predictions and has the potential to serve as a basis for better decision making. 

However, note that, in many real world scenarios, the distribution of likely future states is highly multi-modal, e.g.\ in case of a pedestrian crossing the street in front of a car the two most likely modes correspond to stopping and yielding to the oncoming car or pedestrian crossing the street and the oncoming car stopping and yielding to the pedestrian. However, we show in \cite{BhattacharyyaFS19} the approach in \cite{BhattacharyyaFS18}, does not perform well in case of multi-modal distributions. This is because the approach in \cite{BhattacharyyaFS18} uses the optimization scheme as outlined in \cite{gal2016dropout,kendall2017uncertainties}. This optimization scheme is unable to recover the true model uncertainty \cite{osband2016risk}. This is because the objective used during training is known to conflate risk and uncertainty \citep{osband2016risk}. This limits the accuracy of the models over a plain deterministic (non-Bayesian) approach. The main cause is the data log-likelihood maximization step during optimization -- for every data point the average likelihood assigned by all models in the distribution of likely models is maximized. This forces every model to explain every data point well, pushing every model in the distribution of likely models  to the mean. We address this problem in  \cite{BhattacharyyaFS19} through an objective leveraging synthetic likelihoods \citep{wood2010statistical,rosca2017variational}  -- which are obtained from a classifier. The classifier estimates the likelihood based on whether the models explain (generate) data samples likely under the true data distribution. This removes the constraint on models to explain every data point -- it only requires the explained (generated) data points to be likely under the data distribution. Thus, this allows models in the distribution of likely models to be diverse and deal with multi-modality. Our proposed method shows state of the art performance on the challenging task of predicting the future of street scenes in the CittyScapes dataset. More importantly, we show that the probabilistic output of our Bayesian model produces calibrated uncertainties.

\subsection{Modeling Multimodal Distributions with cVAEs}  




CVPR 2018 (b), NeurIPS workshops 2019 (a,b), CVPR 2021.
\subsection{Exact Inference Models for Multimodal Distributions}  CVPR 2020, GCPR 2020. 
\subsection{Datasets for Dense Urban Environments}  CVPR 2021.
\subsection{Contributions to other projects}
SampleFix and Update Leaks.

\section{Outline of the thesis}
