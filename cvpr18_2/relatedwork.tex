\myparagraph{Human Trajectory Prediction.}
Recent works such as \cite{keller2011will,rehder2015goal} focus on the task of pedestrian trajectory prediction in 3D space. Initial trajectories and obstacle occupancy maps are obtained by dense stereo matching, assuming a linear road model of fixed width. However, 3D coordinates and obstacle maps obtained from stereo matching can be very noisy especially in unknown environments. Moreover, evaluation is on sequences with linear or no vehicle ego-motion. Our method does not depend upon unreliable 3D coordinates and needs no assumptions about scene geometry and vehicle ego-motion. Another class of models such as \cite{helbing1995social,yamaguchi2011you,robicquet2016learning,alahi2016social} consider the problem of pedestrian trajectory prediction in a social context by modelling human-human interactions. The state of the art model \cite{alahi2016social} proposes to estimate the trajectories of each person in the scene by an instance of a ``Social'' LSTM. The instances of the Social LSTM can communicate with a special pooling layer. This enables the modelling of interactions and joint estimation of trajectories of all pedestrians in the scene. In \cite{trautman2013robot} the joint estimation of robot and human trajectories are considered in a social context. However, in case of on-board prediction vehicle ego-motion dominates social aspects. Moreover, most methods are trained/tested on static camera datasets which are hand annotated with minimum observation noise. Apart from these, the class of models such as \cite{hu2007semantic,kim2011gaussian,morris2011trajectory,zhou2011random,zhang2013understanding} aim at discovering motion patterns of humans and vehicles. Such methods cannot be used for trajectory prediction and do not consider vehicle ego-motion.

\myparagraph{Modeling Uncertainty in Deep Learning.} 
Popular deep learning architectures do not model uncertainty. They assume uniform constant observation noise (aleatoric uncertainty). Heteroscedastic regression methods \cite{nix1994estimating,le2005heteroscedastic}  estimate aleatoric uncertanity by predicting the parameters of a assumed observation noise distribution  (also in \cite{alahi2016social}). Bayesian neural networks \cite{mackay1992practical,neal2012bayesian} offer a probabilistic view of deep learning and provide model (epistemic) uncertainty estimates. However, inference of model posterior in such networks is difficult. Variational Inference is a popular method. Gal et. al. in \cite{gal2016dropout} showed that dropout training in deep neural networks approximates Bayesian inference in deep Gaussian processes. Extending these results it was shown in \cite{Gal2016Bayesian} that dropout training can be cast as approximate Bernoulli variational inference in Bayesian neural networks. These results were extended to RNNs in \cite{gal2016theoretically}. The developed Bayesian RNNs showed superior performance to standard RNNs with dropout in various tasks. More recently, \cite{kendall2017uncertainties} presents a Bayesian deep learning framework jointly estimating aleatoric uncertainty together with epistemic uncertainty. The resulting framework gives new state-of-the-art results on segmentation and depth regression benchmarks.

\myparagraph{Assisted and Autonomous driving.}
One of the earliest works on vehicle ego-motion (odometry) prediction or popularly, autonomous driving, was ALVINN by \cite{pomerleau1989alvinn}. This work showed the possibility of directly predicting steering angles from visual input. This system used a simple fully-connected network. More recently, \cite{bojarski2016end} uses a convolutional neural network for this task and achieves a autonomy of 90\% using a relatively small training set. However, the focus is on highway driving. \cite{xu2016end} proposes a FCN-LSTM that predicts the next vehicle odometry based on the visual input captured by an on-board camera and previous odometry of the vehicle. Here, a diverse crowed sourced dataset is used. However, these methods predict vehicle odometry (e.g. steering angle) only for the next time-step. In contrast, we focus on inner-city driving and predict multiple time-steps into the future. \cite{santana2016learning} proposes a driving simulator that predicts the future in form of frames, based on the current and past visuals observed from an on-board camera. It is well known that future frame prediction suffers from blurriness problems in the long-term important details get lost \cite{mathieu2015deep}. We predict the future in terms of bounding box coordinates which remain well defined by design in the long-term.