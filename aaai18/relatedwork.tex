\myparagraph{RGB frame prediction.} This problem has  recently received a lot of attention. However, the predicted frames have blurriness problems. \cite{ranzato2014video} sought to remedy this problem by discretizing the input through k-means atoms and predicting on this vocabulary instead. The work of \cite{mathieu2015deep} proposes using adversarial loss, which leads to improved results over \cite{ranzato2014video}. \cite{liang2017dual,liu2017video,patraucean2015spatio} shows some further improvement through the use of optical flow information. However, these approaches produce sharper short term predictions but still suffer from blurriness problems starting as soon as 3 frames into the future. \cite{kalchbrenner2016video} focus on moving MNIST digits and like \cite{finn2016unsupervised} on action conditioned video prediction.  \cite{villegas2017learning} proposes a hierarchical approach for making long-term frame predictions, by first estimating the high-level structure in the input frames and predicting how that structure evolves in the future. They show promising results on videos where pose is an easily identifiable and appropriate high level structure to exploit. However, such high-level structures are video domain dependent. Other works  \cite{sutskever2009recurrent,michalski2014modeling} focus on deterministic bouncing ball sequences, but their dataset is limited in size and resolution and generalization with respect to the number of balls and their velocities is not considered.

\myparagraph{Intuitive physics.} Developing an intuitive understanding of physics from raw visual input has been explored recently. \cite{fragkiadaki2015learning} predict future states of balls moving on a billiard table and \cite{lerer2016learning,li2016fall} predict the stability of towers made out of blocks.  However, both \cite{fragkiadaki2015learning} and \cite{lerer2016learning} have an ``object notion'', meaning that the architecture knows a priori the location or type of the objects that  it is supposed to infer. Although some recent approaches such as \cite{battaglia2016interaction,watters2017visual} are capable of long-term predictions, they are modeling either state-to-state or images-to-state transitions. Moreover, in the latter case, the input is visually simplified, and the focus is only on deterministic motions. In contrast to this body of work, we focus on  more diverse scenarios and are agnostic to the underlying objects and causes of change. 

\myparagraph{Video segmentation.} Video segmentation as the task of finding consistent spatio-temporal boundaries in a video volume has received significant attention over the last years \cite{galasso2014spectral,ochs2014segmentation,galasso2013unified,chang2013video}, as it provides an initial analysis and abstraction for further processing. In contrast, our approach aims at predicting these boundaries into the future without any video observed for  future frames. %Our proposed model could serve as an expectation on boundaries in future frames and therefore help improve video segmentation prediction in future work.